#!/bin/sh

# Download Hadoop into directory
cd /usr/local
sudo wget http://apache.mirrors.pair.com/hadoop/common/stable/hadoop-1.2.1.tar.gz
sudo tar xzf hadoop-1.2.1.tar.gz
sudo mv hadoop-1.2.1 hadoop

# Change owner of all the files to ubuntu user
# Check if correct
sudo chown -R ubuntu hadoop

# Add the following lines to
# the end of the “$HOME/.bashrc” file of user ubuntu
# Set Hadoop-related environment variables
 export HADOOP_HOME=/usr/local/hadoop
# Set JAVA_HOME (we will also configure JAVA_HOME directly for Hadoop later on)
 export JAVA_HOME=/usr/lib/jvm/java-7-oracle
# Some convenient aliases and functions for running Hadoop-related commands
 unalias fs &> /dev/null
 alias fs="hadoop fs"
 unalias hls &> /dev/null
 alias hls="fs -ls"
# If you have LZO compression enabled in your Hadoop cluster and
# compress job outputs with LZOP (not covered in this tutorial):
# Conveniently inspect an LZOP compressed file from the command
# line; run via:
#
# $ lzohead /hdfs/path/to/lzop/compressed/file.lzo
#
# Requires installed 'lzop' command.
#
 lzohead () {
 hadoop fs -cat $1 | lzop -dc | head -1000 | less
 }
# Add Hadoop bin/ directory to PATH
 export PATH=$PATH:$HADOOP_HOME/bin

# Reload bash profile
source ~/.bashrc